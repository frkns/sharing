{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec43cfc2-0fd2-4ffb-a0c5-fa3fabcbb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import ale_py\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc6564f-f5d6-48a9-89ad-ccbb5e714535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n",
      "2.6.0+cpu\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(gym.__version__, torch.__version__, torch.get_num_threads(), torch.get_num_interop_threads(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba35261-68a7-4c02-b44f-a19be65b23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"runs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb65ae8-be7c-4d78-a27b-0c75e9feb2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remake_env(render_mode=None):\n",
    "    global env\n",
    "    if 'env' in globals(): \n",
    "        env.reset(), env.close()\n",
    "        del env\n",
    "    env = gym.make('Breakout-ramDeterministic-v4', render_mode=render_mode)  # default Breakout-ramDeterministic-v4 has frameskip of 4\n",
    "    return env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7545d1-1a31-4a49-bb2e-3cf5acfeb84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint(v=-1, path='./checkpoints'):\n",
    "    ''' If found returns (file_name, version). Otherwise, returns (None, 0). '''\n",
    "    ls = os.listdir(path) \n",
    "    if not ls: return (None, 0)\n",
    "    mx = -1\n",
    "    mx_file = ''\n",
    "    for f in ls:\n",
    "        try: cur = int(f.split('-')[0])  # might be a 'mem-...' file\n",
    "        except: continue\n",
    "        if cur > mx:\n",
    "            mx = cur\n",
    "            mx_file = f \n",
    "        if cur == v: return f, v\n",
    "    return mx_file, mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a0764c-1253-4fdb-9825-ddf94e62cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:  # we will store frames in uint8 to save memory. the forward pass of the network can convert it to float32 if desired\n",
    "    def __init__(self, maxlen):\n",
    "        self.buffer = deque(maxlen=maxlen)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.buffer)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, terminated):\n",
    "        self.buffer.append((state, action, reward, next_state, terminated))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        assert batch_size <= len(self), 'sample size is greater than population of buffer'\n",
    "        states, actions, rewards, next_states, terminateds = zip(*random.sample(self.buffer, batch_size))  # without replacement\n",
    "        return np.stack(states), np.array(actions), np.array(rewards), np.stack(next_states), np.array(terminateds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2705a3a8-3466-4b59-a1f2-00c7c4a8c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(128, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 4)\n",
    "        \n",
    "    def forward(self, x):  # expect uint8 tensor as input\n",
    "        x = x / 255.0\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64d2acc3-1f7b-43c5-b47f-e5cc47629e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a45818-8bf1-4cec-baf7-7b97480c4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_net = QNetwork()\n",
    "target_net = QNetwork()\n",
    "target_net.eval()\n",
    "online_net.to(device)\n",
    "target_net.to(device)\n",
    "\n",
    "def sync(): target_net.load_state_dict(online_net.state_dict())\n",
    "sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1cc17-dc80-451a-972b-4bb8e2e781c4",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac5bebc7-b6c4-44fd-a588-d79245532bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "memory = ReplayBuffer(1_000_000)\n",
    "sync_freq = 10_000  # environment steps\n",
    "gamma = 0.99\n",
    "learn_freq = 4\n",
    "learning_rate = 0.00025\n",
    "eps_max = 1.0  # initial epsilon\n",
    "eps_min = 0.1  # final\n",
    "eps_anneal_steps = 1_000_000\n",
    "learning_starts = 50_000  # uniform random policy is run for X steps before learning starts\n",
    "# noop_max = 30  # might be better off just not training on no-op starts\n",
    "reward_clip = (-1, 1)\n",
    "max_steps = 108000\n",
    "\n",
    "optimizer = optim.AdamW(online_net.parameters(), lr=learning_rate)\n",
    "criterion = nn.HuberLoss(delta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a33c1dfa-0f8b-4ebd-b9f2-a9034bb1b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon():  # epsilon schedule\n",
    "    effective_steps = step_count\n",
    "    return max(eps_min, eps_min + (eps_max - eps_min) * (1 - effective_steps / eps_anneal_steps))  # linear annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae8f93e6-1429-4ae0-bbd9-e0a2161ce60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no checkpoint found\n"
     ]
    }
   ],
   "source": [
    "# load latest checkpoint file if there is one, set step_count, episode_count\n",
    "proj_name = 'breakout-ram_03-03'\n",
    "\n",
    "checkpoint_file, checkpoint_version = get_checkpoint()\n",
    "# checkpoint_version = 12\n",
    "if checkpoint_file is not None:\n",
    "    checkpoint = torch.load('./checkpoints/' + checkpoint_file, weights_only=False, map_location=torch.device(device))\n",
    "    online_net.load_state_dict(checkpoint['online_state_dict'])\n",
    "    target_net.load_state_dict(checkpoint['target_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    episode_count, step_count = checkpoint.get('episode_count'), checkpoint.get('step_count')\n",
    "    try: memory = torch.load('./checkpoints/mem-' + checkpoint_file, weights_only=False)\n",
    "    except FileNotFoundError: pass\n",
    "    print('loaded', checkpoint_file)\n",
    "else: \n",
    "    episode_count, step_count = 0, 0\n",
    "    print('no checkpoint found')\n",
    "    \n",
    "prev_mem_name = '--sentinel--'\n",
    "def save_checkpoint():\n",
    "    global prev_mem_name\n",
    "    name = f'./checkpoints/{checkpoint_version}-{proj_name}-{episode_count}e-{step_count}s.pth'\n",
    "    mem_name = f'./checkpoints/mem-{checkpoint_version}-{proj_name}-{episode_count}e-{step_count}s.pth'\n",
    "    checkpoint = {\n",
    "        'online_state_dict': online_net.state_dict(),\n",
    "        'target_state_dict': target_net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'step_count': step_count,\n",
    "        'episode_count': episode_count\n",
    "    }\n",
    "    torch.save(checkpoint, name)\n",
    "    torch.save(memory, mem_name)\n",
    "    if os.path.exists(prev_mem_name): os.remove(prev_mem_name)\n",
    "    prev_mem_name = mem_name\n",
    "    print('saved', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e59d45f-0707-4ec4-b9f6-757b0cb427ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(s):\n",
    "    with torch.no_grad():\n",
    "        s = torch.tensor(s, dtype=torch.float, device=device)\n",
    "        return online_net(s).argmax().item()\n",
    "\n",
    "def epsilon_greedy(s):\n",
    "    return env.action_space.sample() if np.random.random() < get_epsilon() else greedy(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "376ff2b4-9708-4828-a607-d56a11e1e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_action(action, update_memory=True):\n",
    "    global state\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    if update_memory:\n",
    "        memory.push(state, action, reward, next_state, terminated)\n",
    "    state = next_state\n",
    "    reward = np.clip(reward, *reward_clip)\n",
    "    return reward, terminated, truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96a2dc13-1a3d-4ff8-877c-b652dc6a424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint None\n",
      "checkpoint version 0\n",
      "episode_count 0\n",
      "step_count 0\n"
     ]
    }
   ],
   "source": [
    "print(f'checkpoint {checkpoint_file}')\n",
    "print(f'checkpoint version {checkpoint_version}')\n",
    "print(f'episode_count {episode_count}')\n",
    "print(f'step_count {step_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1261adf7-0ef8-4704-88ee-b1e118313a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1000\t(0.5/s)  [total 3000]\n",
      "step 366484\t(182/s)  [total 791651]\n",
      "time 2014.70 s\n",
      "---\n",
      "avg. return: 9.30000  (last 500 episodes)\n",
      "epsilon 0.28751\n",
      "saved ./checkpoints/6-breakout-ram_03-03-3000e-791651s.pth\n"
     ]
    }
   ],
   "source": [
    "train_episodes = 1_000\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs')\n",
    "return_history = deque(maxlen=100)\n",
    "remake_env(None)\n",
    "start_episode, start_step = episode_count, step_count\n",
    "\n",
    "try:\n",
    "    t0 = time.time()\n",
    "    while len(memory) < learning_starts:\n",
    "        state, info = env.reset()\n",
    "        for step in range(max_steps):\n",
    "            reward, terminated, truncated = do_action(env.action_space.sample())\n",
    "            if len(memory) % 100 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f'collecting initial training samples {len(memory)}/{learning_starts} ({time.time() - t0:.2f} s)')\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "                \n",
    "    t0 = time.time()\n",
    "    for episode in range(train_episodes):\n",
    "        state, info = env.reset()\n",
    "        episode_return = 0\n",
    "        episode_count += 1\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action = epsilon_greedy(state)\n",
    "            reward, truncated, terminated = do_action(action)\n",
    "            episode_return += reward\n",
    "            step_count += 1\n",
    "            \n",
    "            if step_count % sync_freq == 0:  # update target network\n",
    "                sync()\n",
    "                \n",
    "            if step_count % learn_freq == 0:  # update online net\n",
    "                states, actions, rewards, next_states, terminateds = memory.sample(batch_size)\n",
    "                states = torch.tensor(states, dtype=torch.float, device=device)            # (m, 128)\n",
    "                next_states = torch.tensor(next_states, dtype=torch.float, device=device)  # (m, 128)\n",
    "                actions = torch.tensor(actions, dtype=torch.long, device=device).reshape(-1, 1)           # (m, 1)\n",
    "                rewards = torch.tensor(rewards, dtype=torch.float, device=device).reshape(-1, 1)          # (m, 1)\n",
    "                terminateds = torch.tensor(terminateds, dtype=torch.float, device=device).reshape(-1, 1)  # (m, 1)\n",
    "                \n",
    "                pred = online_net(states).gather(1, actions)  # predicted Q-values of the selected action\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    y = rewards + gamma * target_net(next_states).max(axis=1, keepdim=True).values * (1 - terminateds)\n",
    "                \n",
    "                loss = criterion(pred, y)  # don't need to detach but y.requires_grad is False\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                total_norm = torch.nn.utils.get_total_norm(online_net.parameters())\n",
    "                writer.add_scalar('loss', loss.item(), step_count)\n",
    "                writer.add_scalar('total_norm', total_norm, step_count)\n",
    "                optimizer.step()\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        writer.add_scalar('episode_steps', step, step_count)\n",
    "        writer.add_scalar('episode_return', episode_return, step_count)\n",
    "        writer.add_scalar('epsilon', get_epsilon(), step_count)\n",
    "        return_history.append(episode_return)\n",
    "\n",
    "        if episode % 500 == 0 and episode != 0:\n",
    "            checkpoint_version += 1\n",
    "            save_checkpoint()\n",
    "            writer.flush()\n",
    "\n",
    "        if episode % 10 == 0 or episode == train_episodes-1:\n",
    "            tt = time.time() - t0\n",
    "            et = episode_count - start_episode \n",
    "            st = step_count - start_step \n",
    "            # plt.plot(return_history)\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            print(f'episode {et}\\t({et/tt:.1f}/s)  [total {episode_count}]')\n",
    "            print(f'step {st}\\t({st/tt:.0f}/s)  [total {step_count}]')\n",
    "            print(f'time {tt:.2f} s')\n",
    "            print('---')\n",
    "            print(f'avg. return: {np.mean(return_history):.5f}  (last 100 episodes)')\n",
    "            print(f'epsilon {get_epsilon():.5f}')\n",
    "            # plt.show()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('keyboard interrupt')\n",
    "finally:\n",
    "    if episode_count - start_episode > 20:\n",
    "        checkpoint_version += 1\n",
    "        save_checkpoint()\n",
    "    writer.close()\n",
    "    env.reset()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c27d49-46a0-4f87-a5fa-6ff2d7a87142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggleenv310",
   "language": "python",
   "name": "kaggle310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
