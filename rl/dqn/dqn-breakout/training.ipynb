{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8761f4-971e-4482-8514-782ee9453069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import FrameStackObservation, AtariPreprocessing\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import ale_py\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd05d91-212a-4950-9a0e-c9586feab66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "npath = str(Path.cwd().parents[0])  # [0] = ../  [1] = ../../\n",
    "sys.path.append(npath)\n",
    "from stuff import *\n",
    "sys.path.remove(npath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488389de-41aa-4444-9009-e959b9a92d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"runs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ebb80ec-d6fe-49c1-86f9-2802f5c5a644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "2.6.0+cpu\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(gym.__version__, torch.__version__, torch.get_num_threads(), torch.get_num_interop_threads(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0103f37-15c1-44ba-8ab7-baf99140fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, ...)\n",
    "                                              # input (m, 4,84,84) where m=batch_size\n",
    "        self.conv1 = nn.Conv2d(4, 32, 8, 4)   # -> relu (m, 32,20,20)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 2)  # -> relu (m, 64,9,9)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1)  # -> relu (m, 64,7,7) -> flatten (m, 3136)\n",
    "        # nn.Linear(in_features, out_features, ...)\n",
    "        self.fc1 = nn.Linear(3136, 512)  # -> relu (m, 512)\n",
    "        self.fc2 = nn.Linear(512, 4)  # -> output (m, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = x / 255.0  # should we scale to [0, 1]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)  # flatten it to (m, 3136)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # no output activation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5924082b-8eab-4f15-9c16-154fc44fcc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(render_mode=None):\n",
    "    global env\n",
    "    if 'env' in globals(): \n",
    "        env.reset()\n",
    "        env.close()\n",
    "        del env\n",
    "    env = gym.make(\"BreakoutNoFrameskip-v4\", render_mode=render_mode)\n",
    "    env = AtariPreprocessing(env)\n",
    "    env = FrameStackObservation(env, 4)\n",
    "    return env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba0e5c3a-6eb9-457b-8fa1-36c235423bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ef25c7-03ad-41bb-8dd3-ef09e8b1c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_net = QNetwork().to(device)\n",
    "target_net = QNetwork().to(device)\n",
    "target_net.eval()\n",
    "\n",
    "def sync(): target_net.load_state_dict(online_net.state_dict())\n",
    "sync()\n",
    "\n",
    "episode_count, step_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb82aa0b-693a-4662-ba55-63c487acf013",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'breakout-03-05'\n",
    "\n",
    "checkpoint_version = 0\n",
    "prev_mem_name = '\\0'\n",
    "def load_checkpoint(checkpoint_file):\n",
    "    global checkpoint_version, episode_count, step_count\n",
    "    checkpoint = torch.load('./checkpoints/' + checkpoint_file, weights_only=False, map_location=torch.device(device))\n",
    "    online_net.load_state_dict(checkpoint['online_state_dict'])\n",
    "    target_net.load_state_dict(checkpoint['target_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    episode_count, step_count = checkpoint.get('episode_count'), checkpoint.get('step_count')\n",
    "    checkpoint_version = checkpoint.get('checkpoint_version')\n",
    "    checkpoint_version += 1\n",
    "    no_mem = False\n",
    "    try: memory = torch.load('./checkpoints/mem-' + checkpoint_file, weights_only=False)\n",
    "    except: no_mem = True\n",
    "    print('loaded', checkpoint_file, 'memory file could not be accessed' if no_mem else '')\n",
    "\n",
    "def save_checkpoint():\n",
    "    global prev_mem_name, checkpoint_version\n",
    "    name = f'./checkpoints/{checkpoint_version}-{proj_name}-{episode_count}e-{step_count}s.pth'\n",
    "    mem_name = f'./checkpoints/mem-{checkpoint_version}-{proj_name}-{episode_count}e-{step_count}s.pth'\n",
    "    checkpoint = {\n",
    "        'online_state_dict': online_net.state_dict(),\n",
    "        'target_state_dict': target_net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'step_count': step_count,\n",
    "        'episode_count': episode_count,\n",
    "        'checkpoint_version': checkpoint_version\n",
    "    }\n",
    "    torch.save(checkpoint, name)\n",
    "    # torch.save(memory, mem_name)  # saving memory takes a bit of time\n",
    "    checkpoint_version += 1\n",
    "    if os.path.exists(prev_mem_name): os.remove(prev_mem_name)\n",
    "    prev_mem_name = mem_name\n",
    "    print('saved', name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd8146-5f87-4679-a5e4-0da74cc90368",
   "metadata": {},
   "source": [
    "# Modified hyperparameters from Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ba53780-0bc1-4c86-a282-d2e293377379",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "memory = ReplayBuffer(100_000)  # holding 1 million transitions requires ~4*84*84*2*1e6 ~ 56 gb of memory, 100k should be enough\n",
    "sync_freq = 10_000  # environment steps\n",
    "gamma = 0.99\n",
    "learn_freq = 4\n",
    "learning_rate = 0.00025\n",
    "eps_max = 1.0  # initial epsilon\n",
    "eps_min = 0.1  # final\n",
    "eps_anneal_steps = 1_000_000  # linearly anneal from eps_max to eps_min over X steps\n",
    "learning_starts = 50_000  # current policy is run for X steps before learning starts\n",
    "reward_clip = (-999, 999)\n",
    "max_steps = 10000\n",
    "max_norm = 1.0\n",
    "\n",
    "optimizer = optim.AdamW(online_net.parameters(), lr=learning_rate)\n",
    "criterion = nn.HuberLoss(delta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0f4e3f-9384-4047-86fe-5ee2f4a95898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon():  # epsilon schedule\n",
    "    effective_steps = step_count\n",
    "    return max(eps_min, eps_min + (eps_max - eps_min) * (1 - effective_steps / eps_anneal_steps))\n",
    "\n",
    "def do_action(action, update_memory=True):\n",
    "    global state\n",
    "    action = epsilon_greedy(state)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    reward = np.clip(reward, *reward_clip)\n",
    "    if update_memory: memory.push(state, action, reward, next_state, terminated)\n",
    "    state = next_state\n",
    "    return reward, terminated, truncated\n",
    "    \n",
    "def greedy(s):\n",
    "    with torch.no_grad():\n",
    "        return online_net(torch.tensor(s, dtype=torch.float, device=device).unsqueeze(0)).argmax().item()\n",
    "    \n",
    "def epsilon_greedy(s): \n",
    "    return env.action_space.sample() if np.random.random() < get_epsilon() else greedy(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6765e867-481b-4f7b-85ec-023a18b7a01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-breakout-03-05-1001e-185283s.pth',\n",
       " '1-breakout-03-05-1483e-290232s.pth',\n",
       " '10-breakout-03-05-7092e-3343516s.pth',\n",
       " '11-breakout-03-05-8092e-3979952s.pth',\n",
       " '3-breakout-03-05-1565e-311008s.pth',\n",
       " '4-breakout-03-05-2566e-613672s.pth',\n",
       " '5-breakout-03-05-3566e-1137988s.pth',\n",
       " '6-breakout-03-05-3743e-1240756s.pth',\n",
       " '7-breakout-03-05-4091e-1445352s.pth',\n",
       " '8-breakout-03-05-5092e-2065169s.pth',\n",
       " '9-breakout-03-05-6092e-2731172s.pth']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e062689-22cb-48a5-a15a-2896d84de6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 11-breakout-03-05-8092e-3979952s.pth memory file could not be accessed\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint('11-breakout-03-05-8092e-3979952s.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c26b3b-668a-4b28-9893-08d4a0009abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_version 12\n",
      "episode_count 8092\n",
      "step_count 3979952\n"
     ]
    }
   ],
   "source": [
    "print(f'checkpoint_version {checkpoint_version}')\n",
    "print(f'episode_count {episode_count}')\n",
    "print(f'step_count {step_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d53435ae-527f-4b55-9109-b107ed602bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11\t(0.03/s)  [total 8118]\n",
      "step 7345\t(22.9/s)  [total 3995617]\n",
      "time 330.51 s\n",
      "---\n",
      "avg. return: 19.27273  (last 100 episodes)\n",
      "epsilon 0.10000\n",
      "\n",
      "keyboard interrupt - cleaning up...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "train_episodes = 1_000_000\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs')\n",
    "return_history = deque(maxlen=100)\n",
    "make_env(None)\n",
    "start_episode, start_step = episode_count, step_count\n",
    "\n",
    "try:\n",
    "    t0 = time.time()\n",
    "    # while len(memory) < learning_starts:\n",
    "    while len(memory) < batch_size:\n",
    "        state, info = env.reset()\n",
    "        for step in range(max_steps):\n",
    "            reward, terminated, truncated = do_action(env.action_space.sample())\n",
    "            if len(memory) % 100 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f'collecting initial training samples {len(memory)}/{learning_starts} ({time.time() - t0:.2f} s)')\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "    episode_times = deque(maxlen=5)\n",
    "    step_times = deque(maxlen=5)\n",
    "    t0 = time.time()\n",
    "    t1 = time.time()\n",
    "    for episode in range(train_episodes):\n",
    "        state, info = env.reset()\n",
    "        episode_return = 0\n",
    "        episode_count += 1\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            action = epsilon_greedy(state)\n",
    "            reward, truncated, terminated = do_action(action)\n",
    "            episode_return += reward\n",
    "            step_count += 1\n",
    "\n",
    "            if step_count % sync_freq == 0:  # update target network\n",
    "                sync()\n",
    "\n",
    "            if step_count % learn_freq == 0:  # update online net\n",
    "                states, actions, rewards, next_states, terminateds = memory.sample(batch_size)  # as_tensor does not copy\n",
    "                states = torch.as_tensor(states, dtype=torch.float, device=device)            # (m, 4,84,84)\n",
    "                next_states = torch.as_tensor(next_states, dtype=torch.float, device=device)  # (m, 4,84,84)\n",
    "                actions = torch.as_tensor(actions, dtype=torch.long, device=device).reshape(-1, 1)           # (m, 1)\n",
    "                rewards = torch.as_tensor(rewards, dtype=torch.float, device=device).reshape(-1, 1)          # (m, 1)\n",
    "                terminateds = torch.as_tensor(terminateds, dtype=torch.float, device=device).reshape(-1, 1)  # (m, 1)\n",
    "\n",
    "                pred = online_net(states).gather(1, actions)  # predicted Q-values of the selected action\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y = rewards + gamma * target_net(next_states).max(axis=1, keepdim=True).values * (1 - terminateds)\n",
    "\n",
    "                loss = criterion(pred, y)  # don't need to detach since y.requires_grad is False\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                total_norm = torch.nn.utils.clip_grad_norm_(online_net.parameters(), max_norm)\n",
    "                writer.add_scalar('loss', loss.item(), step_count)\n",
    "                writer.add_scalar('total_norm', total_norm, step_count)\n",
    "                optimizer.step()\n",
    "\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        writer.add_scalar('episode_steps', step, step_count)\n",
    "        writer.add_scalar('episode_return', episode_return, step_count)\n",
    "        writer.add_scalar('epsilon', get_epsilon(), step_count)\n",
    "        return_history.append(episode_return)\n",
    "\n",
    "        t = time.time() - t1\n",
    "        episode_times.append(1/t)\n",
    "        step_times.append(step/t)\n",
    "        t1 = time.time()\n",
    "\n",
    "        if episode % 1000 == 0 and episode != 0:\n",
    "            save_checkpoint()\n",
    "            writer.flush()\n",
    "\n",
    "        info_freq = 10\n",
    "        if episode % info_freq == 0 or episode == train_episodes-1:\n",
    "            tt = time.time() - t0\n",
    "            et = episode_count - start_episode\n",
    "            st = step_count - start_step\n",
    "            # plt.plot(return_history)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print(f'episode {et}\\t({np.mean(episode_times):.2f}/s)  [total {episode_count}]')\n",
    "            print(f'step {st}\\t({np.mean(step_times):.1f}/s)  [total {step_count}]')\n",
    "            print(f'time {tt:.2f} s')\n",
    "            print('---')\n",
    "            print(f'avg. return: {np.mean(return_history):.5f}  (last 100 episodes)')\n",
    "            print(f'epsilon {get_epsilon():.5f}')\n",
    "            # plt.show()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nkeyboard interrupt - cleaning up...')\n",
    "finally:\n",
    "    if episode_count - start_episode > 20:\n",
    "        save_checkpoint()\n",
    "    writer.close()\n",
    "    env.close()\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a77ec5-ee2a-4bf7-b832-d1b59b823d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark\n",
    "# = baseline : 22.9 steps/s\n",
    "# + as_tensor: 23.3 steps/s\n",
    "# + async env: ???  steps/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d47a5-ffe9-4c96-bdc6-a99418d670ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e720315-d637-4400-8c55-990f1b204a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d377fe0-66e9-4f43-86d5-c2f42dac42f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cf27f-f93b-40cc-b5df-7768758ab1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a13f5-481f-492d-a481-ca15246e2de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggleenv310",
   "language": "python",
   "name": "kaggle310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
